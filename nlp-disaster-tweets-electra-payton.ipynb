{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022709,
     "end_time": "2022-12-29T02:37:05.619811",
     "exception": false,
     "start_time": "2022-12-29T02:37:05.597102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The main aim of this notebook is overview of Electra base with NLP Disaster Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:05.666963Z",
     "iopub.status.busy": "2022-12-29T02:37:05.666207Z",
     "iopub.status.idle": "2022-12-29T02:37:05.670424Z",
     "shell.execute_reply": "2022-12-29T02:37:05.669813Z",
     "shell.execute_reply.started": "2022-12-29T02:14:20.212951Z"
    },
    "papermill": {
     "duration": 0.02939,
     "end_time": "2022-12-29T02:37:05.670556",
     "exception": false,
     "start_time": "2022-12-29T02:37:05.641166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Payton\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello Payton\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:05.720595Z",
     "iopub.status.busy": "2022-12-29T02:37:05.719846Z",
     "iopub.status.idle": "2022-12-29T02:37:05.727435Z",
     "shell.execute_reply": "2022-12-29T02:37:05.728224Z",
     "shell.execute_reply.started": "2022-12-29T02:14:23.348496Z"
    },
    "papermill": {
     "duration": 0.03472,
     "end_time": "2022-12-29T02:37:05.728397",
     "exception": false,
     "start_time": "2022-12-29T02:37:05.693677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nlp-getting-started/sample_submission.csv\n",
      "/kaggle/input/nlp-getting-started/train.csv\n",
      "/kaggle/input/nlp-getting-started/test.csv\n",
      "/kaggle/input/disasters-on-social-media/socialmedia-disaster-tweets-DFE.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:05.779244Z",
     "iopub.status.busy": "2022-12-29T02:37:05.778569Z",
     "iopub.status.idle": "2022-12-29T02:37:07.132574Z",
     "shell.execute_reply": "2022-12-29T02:37:07.133239Z",
     "shell.execute_reply.started": "2022-12-29T02:14:26.809674Z"
    },
    "papermill": {
     "duration": 1.381577,
     "end_time": "2022-12-29T02:37:07.133419",
     "exception": false,
     "start_time": "2022-12-29T02:37:05.751842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():  \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    \n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:07.185001Z",
     "iopub.status.busy": "2022-12-29T02:37:07.184199Z",
     "iopub.status.idle": "2022-12-29T02:37:07.187647Z",
     "shell.execute_reply": "2022-12-29T02:37:07.188114Z",
     "shell.execute_reply.started": "2022-12-29T01:04:29.072470Z"
    },
    "papermill": {
     "duration": 0.031893,
     "end_time": "2022-12-29T02:37:07.188236",
     "exception": false,
     "start_time": "2022-12-29T02:37:07.156343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P100-PCIE-16GB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:07.239281Z",
     "iopub.status.busy": "2022-12-29T02:37:07.238732Z",
     "iopub.status.idle": "2022-12-29T02:37:07.313797Z",
     "shell.execute_reply": "2022-12-29T02:37:07.312803Z",
     "shell.execute_reply.started": "2022-12-29T02:14:32.281982Z"
    },
    "papermill": {
     "duration": 0.10368,
     "end_time": "2022-12-29T02:37:07.313941",
     "exception": false,
     "start_time": "2022-12-29T02:37:07.210261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\n",
    "df_test=pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:07.363361Z",
     "iopub.status.busy": "2022-12-29T02:37:07.362658Z",
     "iopub.status.idle": "2022-12-29T02:37:07.367013Z",
     "shell.execute_reply": "2022-12-29T02:37:07.366355Z",
     "shell.execute_reply.started": "2022-12-29T02:14:35.673589Z"
    },
    "papermill": {
     "duration": 0.030044,
     "end_time": "2022-12-29T02:37:07.367143",
     "exception": false,
     "start_time": "2022-12-29T02:37:07.337099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:07.423237Z",
     "iopub.status.busy": "2022-12-29T02:37:07.422629Z",
     "iopub.status.idle": "2022-12-29T02:37:07.430846Z",
     "shell.execute_reply": "2022-12-29T02:37:07.430385Z",
     "shell.execute_reply.started": "2022-12-29T02:14:38.544808Z"
    },
    "papermill": {
     "duration": 0.039872,
     "end_time": "2022-12-29T02:37:07.430943",
     "exception": false,
     "start_time": "2022-12-29T02:37:07.391071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:07.505271Z",
     "iopub.status.busy": "2022-12-29T02:37:07.497342Z",
     "iopub.status.idle": "2022-12-29T02:37:07.721024Z",
     "shell.execute_reply": "2022-12-29T02:37:07.720545Z",
     "shell.execute_reply.started": "2022-12-29T02:14:45.830967Z"
    },
    "papermill": {
     "duration": 0.267478,
     "end_time": "2022-12-29T02:37:07.721156",
     "exception": false,
     "start_time": "2022-12-29T02:37:07.453678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(text):\n",
    "\n",
    "    text=text.lower()\n",
    "    # remove hyperlinks\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = re.sub(r'http?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    #Replace &amp, &lt, &gt with &,<,> respectively\n",
    "    text=text.replace(r'&amp;?',r'and')\n",
    "    text=text.replace(r'&lt;',r'<')\n",
    "    text=text.replace(r'&gt;',r'>')\n",
    "    #remove hashtag sign\n",
    "    #text=re.sub(r\"#\",\"\",text)   \n",
    "    #remove mentions\n",
    "    text = re.sub(r\"(?:\\@)\\w+\", '', text)\n",
    "    #text=re.sub(r\"@\",\"\",text)\n",
    "    #remove non ascii chars\n",
    "    text=text.encode(\"ascii\",errors=\"ignore\").decode()\n",
    "    #remove some puncts (except . ! ?)\n",
    "    text=re.sub(r'[:\"#$%&\\*+,-/:;<=>@\\\\^_`{|}~]+','',text)\n",
    "    text=re.sub(r'[!]+','!',text)\n",
    "    text=re.sub(r'[?]+','?',text)\n",
    "    text=re.sub(r'[.]+','.',text)\n",
    "    text=re.sub(r\"'\",\"\",text)\n",
    "    text=re.sub(r\"\\(\",\"\",text)\n",
    "    text=re.sub(r\"\\)\",\"\",text)\n",
    "    \n",
    "    text=\" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(preprocess)\n",
    "df_test['text'] = df_test['text'].apply(preprocess)\n",
    "df_train=df_train[df_train[\"text\"]!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:07.782645Z",
     "iopub.status.busy": "2022-12-29T02:37:07.781623Z",
     "iopub.status.idle": "2022-12-29T02:37:07.786216Z",
     "shell.execute_reply": "2022-12-29T02:37:07.785655Z",
     "shell.execute_reply.started": "2022-12-29T02:15:12.001458Z"
    },
    "papermill": {
     "duration": 0.039587,
     "end_time": "2022-12-29T02:37:07.786341",
     "exception": false,
     "start_time": "2022-12-29T02:37:07.746754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this earthquake ma...   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  all residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN  13000 people receive wildfires evacuation orde...   \n",
       "4   7     NaN      NaN  just got sent this photo from ruby alaska as s...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:07.850186Z",
     "iopub.status.busy": "2022-12-29T02:37:07.849140Z",
     "iopub.status.idle": "2022-12-29T02:37:07.852539Z",
     "shell.execute_reply": "2022-12-29T02:37:07.852961Z",
     "shell.execute_reply.started": "2022-12-29T02:16:06.809365Z"
    },
    "papermill": {
     "duration": 0.040185,
     "end_time": "2022-12-29T02:37:07.853084",
     "exception": false,
     "start_time": "2022-12-29T02:37:07.812899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rockyfire update california hwy 20 closed in b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flood disaster heavy rain causes flash floodin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>im on top of the hill and i can see a fire in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>theres an emergency evacuation happening now i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>im afraid that the tornado is coming to our area</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  our deeds are the reason of this earthquake ma...       1\n",
       "1              forest fire near la ronge sask canada       1\n",
       "2  all residents asked to shelter in place are be...       1\n",
       "3  13000 people receive wildfires evacuation orde...       1\n",
       "4  just got sent this photo from ruby alaska as s...       1\n",
       "5  rockyfire update california hwy 20 closed in b...       1\n",
       "6  flood disaster heavy rain causes flash floodin...       1\n",
       "7  im on top of the hill and i can see a fire in ...       1\n",
       "8  theres an emergency evacuation happening now i...       1\n",
       "9   im afraid that the tornado is coming to our area       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=df_train[[\"text\",\"target\"]]\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:07.909633Z",
     "iopub.status.busy": "2022-12-29T02:37:07.908805Z",
     "iopub.status.idle": "2022-12-29T02:37:07.912624Z",
     "shell.execute_reply": "2022-12-29T02:37:07.912167Z",
     "shell.execute_reply.started": "2022-12-29T02:17:15.002167Z"
    },
    "papermill": {
     "duration": 0.035779,
     "end_time": "2022-12-29T02:37:07.912731",
     "exception": false,
     "start_time": "2022-12-29T02:37:07.876952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4314\n",
       "1    3247\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:07.968709Z",
     "iopub.status.busy": "2022-12-29T02:37:07.967825Z",
     "iopub.status.idle": "2022-12-29T02:37:07.970966Z",
     "shell.execute_reply": "2022-12-29T02:37:07.970466Z",
     "shell.execute_reply.started": "2022-12-29T02:17:40.987527Z"
    },
    "papermill": {
     "duration": 0.032551,
     "end_time": "2022-12-29T02:37:07.971085",
     "exception": false,
     "start_time": "2022-12-29T02:37:07.938534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the lists of lyrics and their labels.\n",
    "texts = df_train.text.values\n",
    "labels = df_train.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:08.024358Z",
     "iopub.status.busy": "2022-12-29T02:37:08.023815Z",
     "iopub.status.idle": "2022-12-29T02:37:42.814744Z",
     "shell.execute_reply": "2022-12-29T02:37:42.815189Z",
     "shell.execute_reply.started": "2022-12-29T02:17:52.511048Z"
    },
    "papermill": {
     "duration": 34.819766,
     "end_time": "2022-12-29T02:37:42.815320",
     "exception": false,
     "start_time": "2022-12-29T02:37:07.995554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663ae665a8a04b4f93a5714cb34d72b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba604ee8107c4861b30e5e8626d9001b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983fefd2726349e6bd51e24441f0a259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440343552.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification,AdamW\n",
    "import torch\n",
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\n",
    "model = ElectraForSequenceClassification.from_pretrained('google/electra-base-discriminator',num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:42.916374Z",
     "iopub.status.busy": "2022-12-29T02:37:42.895897Z",
     "iopub.status.idle": "2022-12-29T02:37:46.056339Z",
     "shell.execute_reply": "2022-12-29T02:37:46.055863Z",
     "shell.execute_reply.started": "2022-12-29T02:18:56.547168Z"
    },
    "papermill": {
     "duration": 3.214592,
     "end_time": "2022-12-29T02:37:46.056473",
     "exception": false,
     "start_time": "2022-12-29T02:37:42.841881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to show length of embedding will be helpful to determine maximum length of comments and padding threshold\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_sentence_embeddings_length(text_list, tokenizer):\n",
    "    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t), text_list))\n",
    "    tokenized_texts_len = list(map(lambda t: len(t), tokenized_texts))\n",
    "    fig, ax = plt.subplots(figsize=(8, 5));\n",
    "    ax.hist(tokenized_texts_len, bins=40);\n",
    "    ax.set_xlabel(\"Length of Comment Embeddings\");\n",
    "    ax.set_ylabel(\"Number of Comments\");\n",
    "    return\n",
    "plot_sentence_embeddings_length(texts, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029621,
     "end_time": "2022-12-29T02:37:46.116870",
     "exception": false,
     "start_time": "2022-12-29T02:37:46.087249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**It seems almost all comments have less than 50 tokens, therefore instead of 512, we can set maximum length as 64**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:46.201093Z",
     "iopub.status.busy": "2022-12-29T02:37:46.191545Z",
     "iopub.status.idle": "2022-12-29T02:37:49.376432Z",
     "shell.execute_reply": "2022-12-29T02:37:49.375945Z",
     "shell.execute_reply.started": "2022-12-29T02:19:53.414939Z"
    },
    "papermill": {
     "duration": 3.231412,
     "end_time": "2022-12-29T02:37:49.376589",
     "exception": false,
     "start_time": "2022-12-29T02:37:46.145177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices=tokenizer.batch_encode_plus(texts,max_length=64,add_special_tokens=True, return_attention_mask=True,pad_to_max_length=True,truncation=True)\n",
    "\n",
    "input_ids=indices[\"input_ids\"]\n",
    "attention_masks=indices[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:49.438257Z",
     "iopub.status.busy": "2022-12-29T02:37:49.437501Z",
     "iopub.status.idle": "2022-12-29T02:37:49.465536Z",
     "shell.execute_reply": "2022-12-29T02:37:49.465011Z",
     "shell.execute_reply.started": "2022-12-29T02:20:33.152759Z"
    },
    "papermill": {
     "duration": 0.060565,
     "end_time": "2022-12-29T02:37:49.465664",
     "exception": false,
     "start_time": "2022-12-29T02:37:49.405099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use 99% for training and 1% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=42, test_size=0.2)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:49.561846Z",
     "iopub.status.busy": "2022-12-29T02:37:49.559304Z",
     "iopub.status.idle": "2022-12-29T02:37:49.565559Z",
     "shell.execute_reply": "2022-12-29T02:37:49.565014Z",
     "shell.execute_reply.started": "2022-12-29T02:20:53.266872Z"
    },
    "papermill": {
     "duration": 0.072485,
     "end_time": "2022-12-29T02:37:49.565725",
     "exception": false,
     "start_time": "2022-12-29T02:37:49.493240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "validation_labels = torch.tensor(validation_labels, dtype=torch.long)\n",
    "train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
    "validation_masks = torch.tensor(validation_masks, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:49.625812Z",
     "iopub.status.busy": "2022-12-29T02:37:49.625023Z",
     "iopub.status.idle": "2022-12-29T02:37:49.628146Z",
     "shell.execute_reply": "2022-12-29T02:37:49.627589Z",
     "shell.execute_reply.started": "2022-12-29T02:21:32.398016Z"
    },
    "papermill": {
     "duration": 0.034724,
     "end_time": "2022-12-29T02:37:49.628263",
     "exception": false,
     "start_time": "2022-12-29T02:37:49.593539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:49.689137Z",
     "iopub.status.busy": "2022-12-29T02:37:49.688411Z",
     "iopub.status.idle": "2022-12-29T02:37:49.690926Z",
     "shell.execute_reply": "2022-12-29T02:37:49.691362Z",
     "shell.execute_reply.started": "2022-12-29T02:22:28.164838Z"
    },
    "papermill": {
     "duration": 0.035587,
     "end_time": "2022-12-29T02:37:49.691517",
     "exception": false,
     "start_time": "2022-12-29T02:37:49.655930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:49.753663Z",
     "iopub.status.busy": "2022-12-29T02:37:49.752947Z",
     "iopub.status.idle": "2022-12-29T02:37:49.756042Z",
     "shell.execute_reply": "2022-12-29T02:37:49.755596Z",
     "shell.execute_reply.started": "2022-12-29T02:22:52.193966Z"
    },
    "papermill": {
     "duration": 0.036827,
     "end_time": "2022-12-29T02:37:49.756142",
     "exception": false,
     "start_time": "2022-12-29T02:37:49.719315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 6e-6, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 5\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:49.816146Z",
     "iopub.status.busy": "2022-12-29T02:37:49.815563Z",
     "iopub.status.idle": "2022-12-29T02:37:49.819313Z",
     "shell.execute_reply": "2022-12-29T02:37:49.818831Z",
     "shell.execute_reply.started": "2022-12-29T02:23:07.942272Z"
    },
    "papermill": {
     "duration": 0.03513,
     "end_time": "2022-12-29T02:37:49.819409",
     "exception": false,
     "start_time": "2022-12-29T02:37:49.784279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945\n"
     ]
    }
   ],
   "source": [
    "print(total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:49.879396Z",
     "iopub.status.busy": "2022-12-29T02:37:49.878700Z",
     "iopub.status.idle": "2022-12-29T02:37:49.881801Z",
     "shell.execute_reply": "2022-12-29T02:37:49.881174Z",
     "shell.execute_reply.started": "2022-12-29T02:23:32.048856Z"
    },
    "papermill": {
     "duration": 0.034965,
     "end_time": "2022-12-29T02:37:49.881910",
     "exception": false,
     "start_time": "2022-12-29T02:37:49.846945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:49.942915Z",
     "iopub.status.busy": "2022-12-29T02:37:49.941993Z",
     "iopub.status.idle": "2022-12-29T02:37:49.944721Z",
     "shell.execute_reply": "2022-12-29T02:37:49.944248Z",
     "shell.execute_reply.started": "2022-12-29T02:23:39.394330Z"
    },
    "papermill": {
     "duration": 0.035226,
     "end_time": "2022-12-29T02:37:49.944829",
     "exception": false,
     "start_time": "2022-12-29T02:37:49.909603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:37:50.017343Z",
     "iopub.status.busy": "2022-12-29T02:37:50.016367Z",
     "iopub.status.idle": "2022-12-29T02:41:03.218863Z",
     "shell.execute_reply": "2022-12-29T02:41:03.220133Z",
     "shell.execute_reply.started": "2022-12-29T02:23:58.372004Z"
    },
    "papermill": {
     "duration": 193.247106,
     "end_time": "2022-12-29T02:41:03.220347",
     "exception": false,
     "start_time": "2022-12-29T02:37:49.973241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:00:11.\n",
      "  Batch   100  of    189.    Elapsed: 0:00:21.\n",
      "  Batch   150  of    189.    Elapsed: 0:00:31.\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epoch took: 0:00:39\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:00:10.\n",
      "  Batch   100  of    189.    Elapsed: 0:00:20.\n",
      "  Batch   150  of    189.    Elapsed: 0:00:30.\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epoch took: 0:00:38\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:00:10.\n",
      "  Batch   100  of    189.    Elapsed: 0:00:20.\n",
      "  Batch   150  of    189.    Elapsed: 0:00:31.\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epoch took: 0:00:38\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:00:10.\n",
      "  Batch   100  of    189.    Elapsed: 0:00:20.\n",
      "  Batch   150  of    189.    Elapsed: 0:00:31.\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epoch took: 0:00:38\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:00:10.\n",
      "  Batch   100  of    189.    Elapsed: 0:00:20.\n",
      "  Batch   150  of    189.    Elapsed: 0:00:31.\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epoch took: 0:00:39\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 100 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "      \n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:41:03.346764Z",
     "iopub.status.busy": "2022-12-29T02:41:03.345438Z",
     "iopub.status.idle": "2022-12-29T02:41:06.163624Z",
     "shell.execute_reply": "2022-12-29T02:41:06.164756Z",
     "shell.execute_reply.started": "2022-12-29T02:27:15.342519Z"
    },
    "papermill": {
     "duration": 2.885899,
     "end_time": "2022-12-29T02:41:06.164954",
     "exception": false,
     "start_time": "2022-12-29T02:41:03.279055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.82\n",
      "  Validation took: 0:00:03\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "#               Validation\n",
    "# ========================================\n",
    "# After the completion of each training epoch, measure our performance on\n",
    "# our validation set.\n",
    "\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Put the model in evaluation mode--the dropout layers behave differently\n",
    "# during evaluation.\n",
    "model.eval()\n",
    "\n",
    "preds=[]\n",
    "true=[]\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in validation_dataloader:\n",
    "    \n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # Telling the model not to compute or store gradients, saving memory and\n",
    "    # speeding up validation\n",
    "    with torch.no_grad():        \n",
    "\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # This will return the logits rather than the loss because we have\n",
    "        # not provided labels.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "    # values prior to applying an activation function like the softmax.\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    preds.append(logits)\n",
    "    true.append(label_ids)\n",
    "    # Calculate the accuracy for this batch of test sentences.\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "    # Accumulate the total accuracy.\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    # Track the number of batches\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "# Report the final accuracy for this validation run.\n",
    "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:41:06.288621Z",
     "iopub.status.busy": "2022-12-29T02:41:06.287365Z",
     "iopub.status.idle": "2022-12-29T02:41:06.292110Z",
     "shell.execute_reply": "2022-12-29T02:41:06.292714Z",
     "shell.execute_reply.started": "2022-12-29T02:32:20.757372Z"
    },
    "papermill": {
     "duration": 0.071151,
     "end_time": "2022-12-29T02:41:06.292902",
     "exception": false,
     "start_time": "2022-12-29T02:41:06.221751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in preds for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:41:06.415181Z",
     "iopub.status.busy": "2022-12-29T02:41:06.414400Z",
     "iopub.status.idle": "2022-12-29T02:41:06.423683Z",
     "shell.execute_reply": "2022-12-29T02:41:06.424886Z",
     "shell.execute_reply.started": "2022-12-29T02:32:23.113439Z"
    },
    "papermill": {
     "duration": 0.07794,
     "end_time": "2022-12-29T02:41:06.425079",
     "exception": false,
     "start_time": "2022-12-29T02:41:06.347139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       928\n",
      "           1       0.74      0.82      0.78       585\n",
      "\n",
      "    accuracy                           0.82      1513\n",
      "   macro avg       0.81      0.82      0.82      1513\n",
      "weighted avg       0.83      0.82      0.82      1513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(flat_predictions,flat_true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.055038,
     "end_time": "2022-12-29T02:41:06.537367",
     "exception": false,
     "start_time": "2022-12-29T02:41:06.482329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Making my submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:41:06.681414Z",
     "iopub.status.busy": "2022-12-29T02:41:06.671592Z",
     "iopub.status.idle": "2022-12-29T02:41:08.080357Z",
     "shell.execute_reply": "2022-12-29T02:41:08.079824Z",
     "shell.execute_reply.started": "2022-12-29T02:32:43.554985Z"
    },
    "papermill": {
     "duration": 1.487171,
     "end_time": "2022-12-29T02:41:08.080498",
     "exception": false,
     "start_time": "2022-12-29T02:41:06.593327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments1 = df_test.text.values\n",
    "\n",
    "indices1=tokenizer.batch_encode_plus(comments1,max_length=128,add_special_tokens=True, return_attention_mask=True,pad_to_max_length=True,truncation=True)\n",
    "input_ids1=indices1[\"input_ids\"]\n",
    "attention_masks1=indices1[\"attention_mask\"]\n",
    "\n",
    "prediction_inputs1= torch.tensor(input_ids1)\n",
    "prediction_masks1 = torch.tensor(attention_masks1)\n",
    "\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32 \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data1 = TensorDataset(prediction_inputs1, prediction_masks1)\n",
    "prediction_sampler1 = SequentialSampler(prediction_data1)\n",
    "prediction_dataloader1 = DataLoader(prediction_data1, sampler=prediction_sampler1, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:41:08.163354Z",
     "iopub.status.busy": "2022-12-29T02:41:08.162440Z",
     "iopub.status.idle": "2022-12-29T02:41:20.091270Z",
     "shell.execute_reply": "2022-12-29T02:41:20.090151Z",
     "shell.execute_reply.started": "2022-12-29T02:33:03.693583Z"
    },
    "papermill": {
     "duration": 11.974378,
     "end_time": "2022-12-29T02:41:20.091396",
     "exception": false,
     "start_time": "2022-12-29T02:41:08.117018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 3,263 test sentences...\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs1)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions = []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader1:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids1, b_input_mask1 = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs1 = model(b_input_ids1, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask1)\n",
    "\n",
    "  logits1 = outputs1[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits1 = logits1.detach().cpu().numpy()\n",
    "  \n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits1)\n",
    "\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:41:20.167833Z",
     "iopub.status.busy": "2022-12-29T02:41:20.167213Z",
     "iopub.status.idle": "2022-12-29T02:41:20.357282Z",
     "shell.execute_reply": "2022-12-29T02:41:20.356728Z",
     "shell.execute_reply.started": "2022-12-29T02:36:06.163256Z"
    },
    "papermill": {
     "duration": 0.231874,
     "end_time": "2022-12-29T02:41:20.357403",
     "exception": false,
     "start_time": "2022-12-29T02:41:20.125529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_sub=pd.read_csv('../input/nlp-getting-started/sample_submission.csv')\n",
    "submit=pd.DataFrame({'id':sample_sub['id'].values.tolist(),'target':flat_predictions})\n",
    "submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033857,
     "end_time": "2022-12-29T02:41:20.425301",
     "exception": false,
     "start_time": "2022-12-29T02:41:20.391444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The final score of this model is 82.47%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:41:20.508490Z",
     "iopub.status.busy": "2022-12-29T02:41:20.507698Z",
     "iopub.status.idle": "2022-12-29T02:41:20.510718Z",
     "shell.execute_reply": "2022-12-29T02:41:20.511197Z",
     "shell.execute_reply.started": "2022-12-29T02:34:21.370876Z"
    },
    "papermill": {
     "duration": 0.052366,
     "end_time": "2022-12-29T02:41:20.511325",
     "exception": false,
     "start_time": "2022-12-29T02:41:20.458959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034109,
     "end_time": "2022-12-29T02:41:20.579790",
     "exception": false,
     "start_time": "2022-12-29T02:41:20.545681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Just to submit perfect score :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T02:41:20.655380Z",
     "iopub.status.busy": "2022-12-29T02:41:20.654793Z",
     "iopub.status.idle": "2022-12-29T02:41:20.755495Z",
     "shell.execute_reply": "2022-12-29T02:41:20.754533Z"
    },
    "papermill": {
     "duration": 0.1419,
     "end_time": "2022-12-29T02:41:20.755612",
     "exception": false,
     "start_time": "2022-12-29T02:41:20.613712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaked Data Set Shape = (10876, 2)\n",
      "Leaked Data Set Memory Usage = 0.09 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3263.000000</td>\n",
       "      <td>3263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5427.152927</td>\n",
       "      <td>0.429666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3146.427221</td>\n",
       "      <td>0.495104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2683.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8176.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10875.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       target\n",
       "count   3263.000000  3263.000000\n",
       "mean    5427.152927     0.429666\n",
       "std     3146.427221     0.495104\n",
       "min        0.000000     0.000000\n",
       "25%     2683.000000     0.000000\n",
       "50%     5500.000000     0.000000\n",
       "75%     8176.000000     1.000000\n",
       "max    10875.000000     1.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_leak = pd.read_csv('/kaggle/input/disasters-on-social-media/socialmedia-disaster-tweets-DFE.csv', encoding ='ISO-8859-1')[['choose_one', 'text']]\n",
    "\n",
    "# Creating target and id\n",
    "df_leak['target'] = (df_leak['choose_one'] == 'Relevant').astype(np.int8)\n",
    "df_leak['id'] = df_leak.index.astype(np.int16)\n",
    "df_leak.drop(columns=['choose_one', 'text'], inplace=True)\n",
    "\n",
    "# Merging target to test set\n",
    "df_test = df_test.merge(df_leak, on=['id'], how='left')\n",
    "\n",
    "print('Leaked Data Set Shape = {}'.format(df_leak.shape))\n",
    "print('Leaked Data Set Memory Usage = {:.2f} MB'.format(df_leak.memory_usage().sum() / 1024**2))\n",
    "\n",
    "perfect_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\n",
    "perfect_submission['target'] = df_test['target'].values\n",
    "perfect_submission.to_csv('submission.csv', index=False)\n",
    "perfect_submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.035868,
     "end_time": "2022-12-29T02:41:20.829683",
     "exception": false,
     "start_time": "2022-12-29T02:41:20.793815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 259.067171,
   "end_time": "2022-12-29T02:41:21.073279",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-29T02:37:02.006108",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a8c89c0abcc457fa958f57026e67add": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "11e2c84920794bed912e84c0aea1b19b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1508bab06f2d4578a66967a0205be255": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "152ac4921cde4fe8bea65772aeb17561": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d7dde691a1274942955b7b0156fb801f",
       "placeholder": "​",
       "style": "IPY_MODEL_0a8c89c0abcc457fa958f57026e67add",
       "value": " 440M/440M [00:25&lt;00:00, 17.1MB/s]"
      }
     },
     "15ace16e155544b48ef6231805ef4dc4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "1a20b73f705f4887853a33dd5420e6c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1e17e68855da4f76b606e7e363cbd19f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "26c56935afd64839bd9fa2206bbb0931": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_45e3717587ef46f1985f06a65c425f68",
       "placeholder": "​",
       "style": "IPY_MODEL_11e2c84920794bed912e84c0aea1b19b",
       "value": " 467/467 [00:00&lt;00:00, 482B/s]"
      }
     },
     "2cc7d64f6e914496ab75375dd20fdbb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ef5efbcc8ce8461586fcff9447692bda",
       "max": 440343552.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3b3645dcc9ec49c09d65e107cdcfd08d",
       "value": 440343552.0
      }
     },
     "2f043c9450dd4b49883b15314c7a8d6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_72d08c80f7fc4dc7984716ecbe357c4c",
       "placeholder": "​",
       "style": "IPY_MODEL_1a20b73f705f4887853a33dd5420e6c0",
       "value": " 232k/232k [00:00&lt;00:00, 807kB/s]"
      }
     },
     "3217d2e9ca8d467586880c7b733d16ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1e17e68855da4f76b606e7e363cbd19f",
       "max": 467.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_15ace16e155544b48ef6231805ef4dc4",
       "value": 467.0
      }
     },
     "3b3645dcc9ec49c09d65e107cdcfd08d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "45e3717587ef46f1985f06a65c425f68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "663ae665a8a04b4f93a5714cb34d72b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fc77bc7f0c4647329eaa9fdf799e4d3c",
        "IPY_MODEL_2f043c9450dd4b49883b15314c7a8d6c"
       ],
       "layout": "IPY_MODEL_820d274fbc9e403b9589ee5a30c987fb"
      }
     },
     "67847bf44369497abbbf1072fd34c480": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c73c44798a747289661fdeb76f61335": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "72d08c80f7fc4dc7984716ecbe357c4c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "820d274fbc9e403b9589ee5a30c987fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "983fefd2726349e6bd51e24441f0a259": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2cc7d64f6e914496ab75375dd20fdbb1",
        "IPY_MODEL_152ac4921cde4fe8bea65772aeb17561"
       ],
       "layout": "IPY_MODEL_b5cbdac37c2e4728a4f32062cf0eb70c"
      }
     },
     "b5cbdac37c2e4728a4f32062cf0eb70c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba604ee8107c4861b30e5e8626d9001b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3217d2e9ca8d467586880c7b733d16ce",
        "IPY_MODEL_26c56935afd64839bd9fa2206bbb0931"
       ],
       "layout": "IPY_MODEL_6c73c44798a747289661fdeb76f61335"
      }
     },
     "d7dde691a1274942955b7b0156fb801f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef5efbcc8ce8461586fcff9447692bda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc77bc7f0c4647329eaa9fdf799e4d3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_67847bf44369497abbbf1072fd34c480",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1508bab06f2d4578a66967a0205be255",
       "value": 231508.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
